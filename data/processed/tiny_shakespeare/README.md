# Processed Dataset: tiny_shakespeare

This directory contains the processed data for the `tiny_shakespeare` dataset. After running `prepare.py`:

## Summary

- **Tokenizer Type**: regex_bpe
- **Vocabulary Size**: 2,048
- **Total Characters**: 1,115,390
- **Total Tokens**: 355,655
- **Characters per Token**: 3.14
- **Train Tokens**: 320,089 (90%)
- **Validation Tokens**: 35,566 (10%)
- **Block Size**: 256
